# The main entry point of your workflow.
# After configuring, running snakemake -n in a clone of this repository should successfully execute a dry-run of the workflow.

import os
import pathlib
import pandas as pd
import re
from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider
from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider
from snakemake.utils import validate
import subprocess
import tempfile
import yaml

S3 = S3RemoteProvider()
HTTP = HTTPRemoteProvider()

sys.path.insert(0, ".")
from lib import target_construction as tc
from lib import resource_calculator as rc

shell.executable("/bin/bash")
shell.prefix("set -euo pipefail; ")

try:
    pipeline_version = subprocess.check_output(
        ["git", "describe", "--tags", "HEAD"], encoding="UTF-8"
    ).strip()
except subprocess.CalledProcessError:
    pipeline_version = "{version not detected}"
print("wgs-downstream version {}".format(pipeline_version))


configfile: "config/config.yaml"


with open("config/config_resources.yaml", "r") as f:
    config_resources = yaml.safe_load(f)

validate(config, "../schema/global_config_schema.yaml")
validate(config_resources, "../schema/resources_config_schema.yaml")


tempDir = (
    config_resources["tmpdir"]
    if "tmpdir" in config_resources
    else tempfile.gettempdir()
)
cram_manifest = config["cram_manifest"]
gvcf_manifest = config["gvcf_manifest"]
cram_manifest = pd.read_csv(cram_manifest, sep="\t").set_index("sampleid", drop=False)
gvcf_manifest = pd.read_csv(gvcf_manifest, sep="\t").set_index("sampleid", drop=False)
sex_manifest = config["sample-sex"]
sex_manifest = pd.read_csv(sex_manifest, sep="\t").set_index("sampleid", drop=False)

validate(cram_manifest, "../schema/cram_manifest_schema.yaml")
validate(gvcf_manifest, "../schema/gvcf_manifest_schema.yaml")
validate(sex_manifest, "../schema/sex_manifest_schema.yaml")

cram_manifest["internal-cram-paths"] = [
    "results/{}/{}.cram".format(x, y) for x, y in zip(cram_manifest["sampleid"])
]

reference_build = config["genome-build"]
caller_num_intervals = tc.caller_interval_file_count(config)
use_containers = False

TARGETS = [
    "results/multiqc/multiqc.cross-flowcell.html",
    "results/somalier/ancestry/results.somalier-ancestry.pcplot.png",
    "results/glnexus/all/merged_callset.filtered.regions.vcf.gz",
    "results/expansionhunter_denovo/outlier_analysis/results.outlier_locus.tsv",
    "results/expansionhunter_denovo/outlier_analysis/results.outlier_motif.tsv",
    "results/expansionhunter/expansionhunter_report.html",
    "results/cyrius/cyrius_all_subjects.tsv",
    "results/cyrius/cyrius_report.html",
    "results/telomerecat/tracker.tsv",
]

if "annovar-tarball" in config["expansionhunter_denovo"]:
    TARGETS.extend(
        [
            "results/expansionhunter_denovo/outlier_analysis/results.outlier_locus.annotated.tsv",
            "results/expansionhunter_denovo/expansionhunter_denovo.html",
        ]
    )


## To deal with the fact that s3 remote provider service is very slow
## and sometimes buggy, while not interfering with a streamlined
## reference file naming convention, I'll use a snakemake functionality
## for resolving ambiguous rule determination that I really dislike otherwise.
## This is flagged for possible better resolution in the future.
ruleorder: samtools_index_fasta > download_reference_data
ruleorder: create_sequence_dictionary > download_reference_data
ruleorder: index_vcf > download_reference_data
ruleorder: adjust_fasta_formatting > download_reference_data
ruleorder: deeptrio_make_examples_full_trio > copy_gvcfs
ruleorder: deeptrio_make_examples_mother_only > copy_gvcfs
ruleorder: deeptrio_make_examples_father_only > copy_gvcfs


rule all:
    input:
        TARGETS,


rule somalier:
    input:
        [x for x in filter(lambda y: "multiqc" in y or "somalier" in y, TARGETS)],


rule expansionhunter_denovo:
    input:
        [x for x in filter(lambda y: "expansionhunter_denovo" in y, TARGETS)],


rule expansionhunter:
    input:
        [x for x in filter(lambda y: "expansionhunter/" in y, TARGETS)],


rule cyrius:
    input:
        [x for x in filter(lambda y: "cyrius" in y, TARGETS)],


rule telomerecat:
    input:
        [x for x in filter(lambda y: "telomerecat" in y, TARGETS)],


rule glnexus:
    input:
        "results/split_joint_calls/.joint_calls_split",
        "results/glnexus/all/merged_callset.filtered.regions.vcf.gz",


include: "rules/acquire_data.smk"
include: "rules/apptainer.smk"
include: "rules/bcftools_stats.smk"
include: "rules/cyrius.smk"
include: "rules/expansionhunter.smk"
include: "rules/expansionhunter_denovo.smk"
include: "rules/gatk.smk"
include: "rules/glnexus.smk"
include: "rules/multiqc.smk"
include: "rules/references.smk"
include: "rules/somalier.smk"
include: "rules/split_joint_calls.smk"
include: "rules/deeptrio.smk"
include: "rules/slivar.smk"
include: "rules/telomerecat.smk"
